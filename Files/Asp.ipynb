{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42317c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--csv CSV] [--text-col TEXT_COL]\n",
      "                             [--labels LABELS [LABELS ...]]\n",
      "                             [--test-size TEST_SIZE]\n",
      "                             [--random-state RANDOM_STATE] [--k-top K_TOP]\n",
      "                             [--save-model SAVE_MODEL] [--no-save]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --f=c:\\Users\\shaq6\\AppData\\Roaming\\jupyter\\runtime\\kernel-v3a1c41e68ae123f74c4915b489c900d1aad62a87e.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import json\n",
    "import joblib\n",
    "import string\n",
    "import warnings\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import argparse\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Synthetic demo dataset\n",
    "# -----------------------------\n",
    "\n",
    "def demo_data(n: int = 500, seed: int = 42) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create HIPAA-safe synthetic progress notes + labels.\n",
    "    Labels: diabetes, chf, copd (multi-label)\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    templates = [\n",
    "        (\"HPI: Patient with {cond}. Denies {neg}. \"\n",
    "         \"Assessment: {assess}. Plan: {plan}.\"),\n",
    "        (\"Subjective: {cond}. ROS negative for {neg}. \"\n",
    "         \"Assessment/Plan: {assess}; {plan}.\"),\n",
    "        (\"Assessment: {assess}. PMH notable for {cond}. \"\n",
    "         \"Plan: {plan}. Dispo: home.\"),\n",
    "    ]\n",
    "\n",
    "    cond_pool = [\n",
    "        (\"type 2 diabetes\", \"hypoglycemia episodes\", \"optimize metformin\"),\n",
    "        (\"congestive heart failure\", \"chest pain\", \"increase furosemide\"),\n",
    "        (\"COPD with chronic bronchitis\", \"fever or chills\", \"tiotropium daily\"),\n",
    "        (\"no significant PMH\", \"dyspnea\", \"routine follow-up\"),\n",
    "    ]\n",
    "\n",
    "    rows = []\n",
    "    for i in range(n):\n",
    "        t = templates[i % len(templates)]\n",
    "        c = cond_pool[rng.integers(0, len(cond_pool))]\n",
    "        text = t.format(cond=c[0], neg=c[1], assess=\"stable\", plan=c[2])\n",
    "\n",
    "        # Add some section headers and noise\n",
    "        if rng.random() < 0.4:\n",
    "            text = f\"MEDS: lisinopril, metformin.\\n{text}\"\n",
    "        if rng.random() < 0.4:\n",
    "            text += \"\\nAllergies: NKDA.\"\n",
    "\n",
    "        # Labels (weakly tied to chosen condition)\n",
    "        y_diab = int(\"diabetes\" in c[0] or (\"metformin\" in text and rng.random() < 0.5))\n",
    "        y_chf = int(\"heart failure\" in c[0] or (\"furosemide\" in text and rng.random() < 0.5))\n",
    "        y_copd = int(\"COPD\" in c[0] or (\"tiotropium\" in text and rng.random() < 0.5))\n",
    "\n",
    "        # Negation flips a fraction of positives\n",
    "        if \"Denies\" in text or \"negative for\" in text:\n",
    "            if rng.random() < 0.35:\n",
    "                y_diab = max(0, y_diab - 1)\n",
    "            if rng.random() < 0.35:\n",
    "                y_chf = max(0, y_chf - 1)\n",
    "            if rng.random() < 0.35:\n",
    "                y_copd = max(0, y_copd - 1)\n",
    "\n",
    "        rows.append({\"note_id\": f\"N{i:04d}\", \"note_text\": text,\n",
    "                     \"diabetes\": y_diab, \"chf\": y_chf, \"copd\": y_copd})\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Text preprocessing\n",
    "# -----------------------------\n",
    "\n",
    "SECTION_HEADERS = [\n",
    "    \"HPI\", \"ASSESSMENT\", \"PLAN\", \"ASSESSMENT/PLAN\", \"A/P\",\n",
    "    \"SUBJECTIVE\", \"ROS\", \"PMH\", \"MEDS\", \"ALLERGIES\", \"DISPO\"\n",
    "]\n",
    "SECTION_PATTERN = re.compile(\n",
    "    r\"(?P<header>^|\\n)(?P<name>(\" + \"|\".join([re.escape(h) for h in SECTION_HEADERS]) +\n",
    "    r\"))\\s*:?\", flags=re.IGNORECASE\n",
    ")\n",
    "\n",
    "class SectionExtractor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Extracts and reorders salient sections (Assessment + Plan weighted).\"\"\"\n",
    "    def __init__(self, keep=(\"HPI\",\"ASSESSMENT\",\"PLAN\",\"ASSESSMENT/PLAN\",\"SUBJECTIVE\"), weight_plan=2):\n",
    "        self.keep = set(s.upper() for s in keep)\n",
    "        self.weight_plan = weight_plan\n",
    "\n",
    "    def _split_sections(self, text: str) -> List[Tuple[str, str]]:\n",
    "        sections = []\n",
    "        matches = list(SECTION_PATTERN.finditer(text))\n",
    "        for i, m in enumerate(matches):\n",
    "            name = m.group(\"name\").upper()\n",
    "            start = m.end()\n",
    "            end = matches[i+1].start() if i+1 < len(matches) else len(text)\n",
    "            body = text[start:end].strip()\n",
    "            sections.append((name, body))\n",
    "        if not matches:\n",
    "            sections = [(\"FREE_TEXT\", text)]\n",
    "        return sections\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        out = []\n",
    "        for txt in X:\n",
    "            secs = self._split_sections(txt)\n",
    "            selected = [b for (h,b) in secs if h in self.keep or h == \"FREE_TEXT\"]\n",
    "            # Weight plan/assessment text\n",
    "            boosted = []\n",
    "            for b in selected:\n",
    "                boosted.append(b)\n",
    "                if re.search(r\"\\b(plan|assessment)\\b\", b, re.I):\n",
    "                    boosted.append((\" \" + b) * (self.weight_plan-1))\n",
    "            out.append(\"\\n\".join(boosted))\n",
    "        return out\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "\n",
    "class SimpleNegationTagger(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Pure-Python negation tagger (no spaCy).\n",
    "    Tokenizes with a simple regex; tags a window after negation cues.\n",
    "    \"\"\"\n",
    "    def __init__(self, window: int = 6):\n",
    "        self.window = window\n",
    "        self.token_re = re.compile(r\"\\w+|[^\\w\\s]\", re.UNICODE)\n",
    "        self.neg_bigrams = {\"negative for\", \"rule out\"}\n",
    "        self.neg_unigrams = {\"no\", \"denies\", \"without\", \"not\"}\n",
    "\n",
    "    def _find_negation_positions(self, lowered_tokens: List[str]) -> List[int]:\n",
    "        positions = []\n",
    "        for i, tok in enumerate(lowered_tokens):\n",
    "            if tok in self.neg_unigrams:\n",
    "                positions.append(i)\n",
    "            if i + 1 < len(lowered_tokens):\n",
    "                pair = f\"{tok} {lowered_tokens[i+1]}\"\n",
    "                if pair in self.neg_bigrams:\n",
    "                    positions.append(i)\n",
    "        return positions\n",
    "\n",
    "    def _tag(self, text: str) -> str:\n",
    "        tokens = self.token_re.findall(text)\n",
    "        lowered = [t.lower() for t in tokens]\n",
    "        neg_positions = self._find_negation_positions(lowered)\n",
    "\n",
    "        tagged = tokens[:]\n",
    "        for i in neg_positions:\n",
    "            end = min(i + 1 + self.window, len(tokens))\n",
    "            for j in range(i + 1, end):\n",
    "                if tokens[j] in string.punctuation:\n",
    "                    break\n",
    "                tagged[j] = f\"{tokens[j]}_NEG\"\n",
    "        return \" \".join(tagged)\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return [self._tag(x) for x in X]\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Build pipeline\n",
    "# -----------------------------\n",
    "\n",
    "def build_pipeline() -> Pipeline:\n",
    "    \"\"\"\n",
    "    Pipeline:\n",
    "        SectionExtractor -> SimpleNegationTagger -> Tfidf -> OneVsRest(LogReg)\n",
    "    \"\"\"\n",
    "    clf = OneVsRestClassifier(\n",
    "        LogisticRegression(max_iter=300, solver=\"liblinear\", class_weight=\"balanced\")\n",
    "    )\n",
    "    pipe = Pipeline(steps=[\n",
    "        (\"sectioner\", SectionExtractor()),\n",
    "        (\"negation\", SimpleNegationTagger(window=6)),\n",
    "        (\"tfidf\", TfidfVectorizer(\n",
    "            ngram_range=(1,2),\n",
    "            min_df=2,\n",
    "            max_df=0.9,\n",
    "            strip_accents=\"unicode\",\n",
    "            sublinear_tf=True,\n",
    "        )),\n",
    "        (\"clf\", clf)\n",
    "    ])\n",
    "    return pipe\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Train / Evaluate\n",
    "# -----------------------------\n",
    "\n",
    "@dataclass\n",
    "class TrainConfig:\n",
    "    test_size: float = 0.2\n",
    "    random_state: int = 42\n",
    "\n",
    "def run_experiment(df: pd.DataFrame, cfg: TrainConfig, label_cols: List[str]):\n",
    "    assert all(col in df.columns for col in label_cols), f\"Missing label columns in data: {label_cols}\"\n",
    "    assert \"note_text\" in df.columns, \"Data must contain a 'note_text' column.\"\n",
    "\n",
    "    X = df[\"note_text\"].astype(str).tolist()\n",
    "    Y = df[label_cols].astype(int).values\n",
    "    labels = label_cols\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, Y, test_size=cfg.test_size, random_state=cfg.random_state\n",
    "    )\n",
    "\n",
    "    pipe = build_pipeline()\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    prob = pipe.predict_proba(X_test)\n",
    "    pred = (prob >= 0.5).astype(int)\n",
    "\n",
    "    # Metrics\n",
    "    micro_f1 = f1_score(y_test, pred, average=\"micro\", zero_division=0)\n",
    "    macro_f1 = f1_score(y_test, pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "    roc_aucs = {}\n",
    "    for i, lab in enumerate(labels):\n",
    "        try:\n",
    "            roc_aucs[lab] = roc_auc_score(y_test[:, i], prob[:, i])\n",
    "        except ValueError:\n",
    "            roc_aucs[lab] = float(\"nan\")\n",
    "\n",
    "    print(\"\\n=== Metrics ===\")\n",
    "    print(f\"Micro-F1: {micro_f1:.3f} | Macro-F1: {macro_f1:.3f}\")\n",
    "    print(\"ROC-AUC per class:\", {k: (None if np.isnan(v) else round(v,3)) for k,v in roc_aucs.items()})\n",
    "\n",
    "    print(\"\\n=== Per-class report (threshold=0.5) ===\")\n",
    "    print(classification_report(y_test, pred, target_names=labels, zero_division=0))\n",
    "\n",
    "    return pipe, labels\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Model explainability (top n-grams)\n",
    "# -----------------------------\n",
    "\n",
    "def top_features(pipe: Pipeline, labels: List[str], k: int = 12):\n",
    "    vec: TfidfVectorizer = pipe.named_steps[\"tfidf\"]\n",
    "    clf: OneVsRestClassifier = pipe.named_steps[\"clf\"]\n",
    "    feature_names = np.array(vec.get_feature_names_out())\n",
    "\n",
    "    print(\"\\n=== Top n-grams per class (positive/negative) ===\")\n",
    "    for i, lab in enumerate(labels):\n",
    "        lr: LogisticRegression = clf.estimators_[i]\n",
    "        coefs = lr.coef_.ravel()\n",
    "        top_pos = np.argsort(coefs)[-k:][::-1]\n",
    "        top_neg = np.argsort(coefs)[:k]\n",
    "        print(f\"\\n[{lab}] + predictors:\")\n",
    "        for idx in top_pos:\n",
    "            print(f\"  {feature_names[idx]:<30} {coefs[idx]:.3f}\")\n",
    "        print(f\"[{lab}] − predictors:\")\n",
    "        for idx in top_neg:\n",
    "            print(f\"  {feature_names[idx]:<30} {coefs[idx]:.3f}\")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 6) Inference utility\n",
    "# -----------------------------\n",
    "\n",
    "def predict_note(pipe: Pipeline, text: str, labels: List[str], threshold: float = 0.5):\n",
    "    prob = pipe.predict_proba([text])[0]\n",
    "    pred = (prob >= threshold).astype(int)\n",
    "    return dict(zip(labels, [float(p) for p in prob])), dict(zip(labels, [int(x) for x in pred]))\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 7) CLI + Main\n",
    "# -----------------------------\n",
    "\n",
    "def parse_args():\n",
    "    ap = argparse.ArgumentParser(description=\"Clinical Notes Phenotype Classifier (no tensors, no spaCy)\")\n",
    "    ap.add_argument(\"--csv\", type=str, default=None, help=\"Path to CSV with note_text and label columns\")\n",
    "    ap.add_argument(\"--text-col\", type=str, default=\"note_text\", help=\"Text column name (default: note_text)\")\n",
    "    ap.add_argument(\"--labels\", nargs=\"+\", default=[\"diabetes\", \"chf\", \"copd\"], help=\"Label column names\")\n",
    "    ap.add_argument(\"--test-size\", type=float, default=0.2, help=\"Test size fraction (default: 0.2)\")\n",
    "    ap.add_argument(\"--random-state\", type=int, default=7, help=\"Random state (default: 7)\")\n",
    "    ap.add_argument(\"--k-top\", type=int, default=12, help=\"Top n-grams to display per class (default: 12)\")\n",
    "    ap.add_argument(\"--save-model\", type=str, default=\"notes_phenotype_clf.joblib\", help=\"Path to save model (joblib)\")\n",
    "    ap.add_argument(\"--no-save\", action=\"store_true\", help=\"Do not save the trained model\")\n",
    "    return ap.parse_args()\n",
    "\n",
    "def load_data_from_csv(path: str, text_col: str, label_cols: List[str]) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path)\n",
    "    missing = [c for c in [text_col] + label_cols if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns in CSV: {missing}\")\n",
    "    df = df.rename(columns={text_col: \"note_text\"})\n",
    "    for c in label_cols:\n",
    "        df[c] = df[c].astype(int)\n",
    "    df[\"note_text\"] = df[\"note_text\"].astype(str)\n",
    "    return df\n",
    "\n",
    "def main():\n",
    "    args = parse_args()\n",
    "\n",
    "    if args.csv:\n",
    "        print(f\"Loading data from {args.csv} ...\")\n",
    "        df = load_data_from_csv(args.csv, args.text_col, args.labels)\n",
    "    else:\n",
    "        print(\"No CSV provided; generating synthetic demo data ...\")\n",
    "        df = demo_data(n=500, seed=42)\n",
    "\n",
    "    # Train/evaluate\n",
    "    pipe, labels = run_experiment(df, TrainConfig(test_size=args.test_size, random_state=args.random_state), args.labels)\n",
    "\n",
    "    # Explainability\n",
    "    top_features(pipe, labels, k=args.k_top)\n",
    "\n",
    "    # Try a few demo notes\n",
    "    examples = [\n",
    "        \"HPI: Patient with type 2 diabetes. Denies hypoglycemia. Assessment: stable. Plan: optimize metformin.\",\n",
    "        \"Subjective: Progressive dyspnea and orthopnea. Assessment/Plan: increase furosemide. Dispo: home.\",\n",
    "        \"Assessment: COPD exacerbation likely. Plan: tiotropium daily. ROS negative for fever.\",\n",
    "        \"HPI: No history of diabetes or heart failure. Plan: routine follow-up.\"\n",
    "    ]\n",
    "    for t in examples:\n",
    "        proba, pred = predict_note(pipe, t, labels, threshold=0.5)\n",
    "        print(\"\\nNOTE:\", t)\n",
    "        print(\"Prob:\", json.dumps(proba, indent=2))\n",
    "        print(\"Pred:\", pred)\n",
    "\n",
    "    # Persist\n",
    "    if not args.no_save:\n",
    "        out_path = args.save_model\n",
    "        joblib.dump({\"pipeline\": pipe, \"labels\": labels}, out_path)\n",
    "        print(f\"\\nSaved model → {out_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61867222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No CSV provided; generating synthetic demo data ...\n",
      "\n",
      "=== Metrics ===\n",
      "Micro-F1: 0.795 | Macro-F1: 0.800\n",
      "ROC-AUC per class: {'diabetes': np.float64(0.813), 'chf': np.float64(0.976), 'copd': np.float64(0.988)}\n",
      "\n",
      "=== Per-class report (threshold=0.5) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    diabetes       0.81      0.65      0.72        34\n",
      "         chf       0.79      1.00      0.88        22\n",
      "        copd       0.67      1.00      0.80        14\n",
      "\n",
      "   micro avg       0.76      0.83      0.79        70\n",
      "   macro avg       0.76      0.88      0.80        70\n",
      "weighted avg       0.78      0.83      0.79        70\n",
      " samples avg       0.58      0.55      0.56        70\n",
      "\n",
      "\n",
      "=== Top n-grams per class (positive/negative) ===\n",
      "\n",
      "[diabetes] + predictors:\n",
      "  plan optimize                  1.083\n",
      "  metformin dispo                1.064\n",
      "  for type                       1.064\n",
      "  diabetes plan                  1.064\n",
      "  optimize                       0.885\n",
      "  metformin                      0.885\n",
      "  type diabetes                  0.885\n",
      "  type                           0.885\n",
      "  optimize metformin             0.885\n",
      "  diabetes                       0.885\n",
      "  diabetes denies                0.247\n",
      "  with type                      0.247\n",
      "[diabetes] − predictors:\n",
      "  plan routine                   -0.620\n",
      "  for no                         -0.569\n",
      "  pmh_neg plan                   -0.569\n",
      "  up dispo                       -0.569\n",
      "  no significant_neg             -0.363\n",
      "  follow up                      -0.363\n",
      "  follow                         -0.363\n",
      "  pmh_neg                        -0.363\n",
      "  no                             -0.363\n",
      "  routine                        -0.363\n",
      "  significant_neg                -0.363\n",
      "  routine follow                 -0.363\n",
      "\n",
      "[chf] + predictors:\n",
      "  increase furosemide            1.457\n",
      "  increase                       1.457\n",
      "  furosemide                     1.457\n",
      "  congestive                     1.457\n",
      "  congestive heart               1.457\n",
      "  failure                        1.457\n",
      "  heart                          1.457\n",
      "  heart failure                  1.457\n",
      "  for congestive                 1.456\n",
      "  failure plan                   1.456\n",
      "  furosemide dispo               1.456\n",
      "  plan increase                  1.350\n",
      "[chf] − predictors:\n",
      "  diabetes                       -0.658\n",
      "  optimize                       -0.658\n",
      "  optimize metformin             -0.658\n",
      "  type diabetes                  -0.658\n",
      "  type                           -0.658\n",
      "  metformin                      -0.658\n",
      "  follow up                      -0.558\n",
      "  follow                         -0.558\n",
      "  no                             -0.558\n",
      "  no significant_neg             -0.558\n",
      "  pmh_neg                        -0.558\n",
      "  routine                        -0.558\n",
      "\n",
      "[copd] + predictors:\n",
      "  with chronic                   1.459\n",
      "  tiotropium                     1.459\n",
      "  tiotropium daily               1.459\n",
      "  copd with                      1.459\n",
      "  daily                          1.459\n",
      "  bronchitis                     1.459\n",
      "  chronic                        1.459\n",
      "  chronic bronchitis             1.459\n",
      "  copd                           1.459\n",
      "  plan tiotropium                1.313\n",
      "  for copd                       1.251\n",
      "  daily dispo                    1.251\n",
      "[copd] − predictors:\n",
      "  diabetes                       -0.651\n",
      "  optimize                       -0.651\n",
      "  optimize metformin             -0.651\n",
      "  type diabetes                  -0.651\n",
      "  type                           -0.651\n",
      "  metformin                      -0.651\n",
      "  congestive heart               -0.584\n",
      "  congestive                     -0.584\n",
      "  furosemide                     -0.584\n",
      "  increase furosemide            -0.584\n",
      "  increase                       -0.584\n",
      "  failure                        -0.584\n",
      "\n",
      "NOTE: HPI: Patient with type 2 diabetes. Denies hypoglycemia. Assessment: stable. Plan: optimize metformin.\n",
      "Prob: {\n",
      "  \"diabetes\": 0.831130976087898,\n",
      "  \"chf\": 0.04606752301135335,\n",
      "  \"copd\": 0.052190378811500904\n",
      "}\n",
      "Pred: {'diabetes': 1, 'chf': 0, 'copd': 0}\n",
      "\n",
      "NOTE: Subjective: Progressive dyspnea and orthopnea. Assessment/Plan: increase furosemide. Dispo: home.\n",
      "Prob: {\n",
      "  \"diabetes\": 0.4097499943091058,\n",
      "  \"chf\": 0.7566941251969483,\n",
      "  \"copd\": 0.08463535373702515\n",
      "}\n",
      "Pred: {'diabetes': 0, 'chf': 1, 'copd': 0}\n",
      "\n",
      "NOTE: Assessment: COPD exacerbation likely. Plan: tiotropium daily. ROS negative for fever.\n",
      "Prob: {\n",
      "  \"diabetes\": 0.36852947111680945,\n",
      "  \"chf\": 0.06962148822877016,\n",
      "  \"copd\": 0.7061393180469603\n",
      "}\n",
      "Pred: {'diabetes': 0, 'chf': 0, 'copd': 1}\n",
      "\n",
      "NOTE: HPI: No history of diabetes or heart failure. Plan: routine follow-up.\n",
      "Prob: {\n",
      "  \"diabetes\": 0.2573452719794291,\n",
      "  \"chf\": 0.05411122814931442,\n",
      "  \"copd\": 0.07941066715492212\n",
      "}\n",
      "Pred: {'diabetes': 0, 'chf': 0, 'copd': 0}\n"
     ]
    }
   ],
   "source": [
    "!python clinical_notes_classifier_nospacy.py --no-save"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
